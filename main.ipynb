{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PROJECT: AI4I 2020 Predictive Maintenance System\n",
                "# AUTHOR: [Senin AdÄ±n/Burak]\n",
                "# DESCRIPTION: End-to-end Machine Learning project to predict machine failures based on sensor data using Logistic Regression and Random Forest.\n",
                "# DATASET: UCI Machine Learning Repository - AI4I 2020 Predictive Maintenance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. IMPORTING LIBRARIES\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
                "\n",
                "# Suppress warnings for cleaner output\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"Libraries imported successfully.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. DATA LOADING\n",
                "# Fetching dataset from UCI Repository\n",
                "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv\"\n",
                "try:\n",
                "    df = pd.read_csv(url)\n",
                "    print(\"Dataset loaded successfully!\")\n",
                "except Exception as e:\n",
                "    print(f\"Error loading data: {e}\")\n",
                "\n",
                "# Display first 5 rows to understand the structure\n",
                "print(\"\\nFirst 5 rows of the dataset:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# A) DATA PREPROCESSING"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Dropping Irrelevant Columns\n",
                "# 'UDI' and 'Product ID' are identifiers and do not contribute to physical failure prediction.\n",
                "df_clean = df.drop(['UDI', 'Product ID'], axis=1)\n",
                "\n",
                "# Step 2: Feature Engineering\n",
                "# Creating a new feature 'Delta_Temp' representing the difference between Process and Air temperature.\n",
                "# This helps in understanding heat dissipation efficiency.\n",
                "df_clean['Delta_Temp'] = df_clean['Process temperature [K]'] - df_clean['Air temperature [K]']\n",
                "\n",
                "# Step 3: Encoding Categorical Variables\n",
                "# The 'Type' column (L, M, H) is categorical. Converting it to numerical format using Label Encoding.\n",
                "le = LabelEncoder()\n",
                "df_clean['Type'] = le.fit_transform(df_clean['Type'])\n",
                "\n",
                "# Step 4: Preventing Data Leakage\n",
                "# Columns like 'TWF', 'HDF', 'PWF', 'OSF', 'RNF' represent specific failure types.\n",
                "# Including them would cause data leakage as they directly indicate the target.\n",
                "# We remove them to predict 'Machine failure' solely based on sensor readings.\n",
                "X = df_clean.drop(['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis=1)\n",
                "y = df_clean['Machine failure']\n",
                "\n",
                "print(\"\\nData Preprocessing completed. Ready for EDA and Modeling.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# B) EXPLORATORY DATA ANALYSIS (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Correlation Matrix Heatmap\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.heatmap(df_clean.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
                "plt.title('Correlation Matrix of Features')\n",
                "plt.savefig('correlation_matrix.png') # Saving the plot for the report\n",
                "plt.show()\n",
                "\n",
                "# 2. Boxplot: Torque Distribution by Machine Failure Status\n",
                "plt.figure(figsize=(8, 5))\n",
                "sns.boxplot(x='Machine failure', y='Torque [Nm]', data=df_clean, palette='Set2')\n",
                "plt.title('Torque Distribution by Machine Failure Status')\n",
                "plt.xlabel('Machine Failure (0: No Failure, 1: Failure)')\n",
                "plt.ylabel('Torque [Nm]')\n",
                "plt.savefig('boxplot_torque.png') # Saving the plot for the report\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# C) MODELING & EVALUATION"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Train/Test Split (70% Training, 30% Testing)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
                "\n",
                "# 2. Feature Scaling\n",
                "# Standardization is crucial for Logistic Regression to perform well.\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "# --- Model 1: Logistic Regression ---\n",
                "print(\"\\n--- Training Logistic Regression ---\")\n",
                "log_model = LogisticRegression()\n",
                "log_model.fit(X_train_scaled, y_train)\n",
                "y_pred_log = log_model.predict(X_test_scaled)\n",
                "\n",
                "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
                "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Model 2: Random Forest Classifier ---\n",
                "print(\"\\n--- Training Random Forest Classifier ---\")\n",
                "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_model.fit(X_train, y_train)\n",
                "y_pred_rf = rf_model.predict(X_test)\n",
                "\n",
                "# Evaluation Metrics\n",
                "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
                "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
                "\n",
                "# Visualizing Confusion Matrix for Random Forest\n",
                "cm = confusion_matrix(y_test, y_pred_rf)\n",
                "plt.figure(figsize=(6, 5))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title('Confusion Matrix (Random Forest)')\n",
                "plt.ylabel('Actual Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.savefig('confusion_matrix_rf.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance Analysis\n",
                "feature_imp = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x=feature_imp, y=feature_imp.index, palette='viridis')\n",
                "plt.title('Feature Importance (Random Forest)')\n",
                "plt.xlabel('Importance Score')\n",
                "plt.ylabel('Features')\n",
                "plt.savefig('feature_importance.png')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nProject execution completed successfully.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}